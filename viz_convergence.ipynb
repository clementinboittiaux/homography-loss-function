{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308a39c-5f25-4c84-836d-8f05a4b342ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import project\n",
    "from pathlib import Path\n",
    "from kornia.geometry.conversions import quaternion_to_rotation_matrix, QuaternionCoeffOrder, normalize_quaternion\n",
    "\n",
    "def compute_s(chat_q_w, c_R_w, w_t_chat, w_t_c, c_P, xmin, xmax):\n",
    "    c_n = torch.tensor([0, 0, -1], dtype=torch.float64).view(3, 1)\n",
    "    chat_R_w = quaternion_to_rotation_matrix(chat_q_w, order=QuaternionCoeffOrder.WXYZ)\n",
    "    chat_t_c = chat_R_w @ (w_t_c - w_t_chat)\n",
    "    chat_R_c = chat_R_w @ c_R_w.T\n",
    "    s = []\n",
    "    for P in c_P.T:\n",
    "        if P[2] >= xmin and P[2] <= xmax:\n",
    "            chat_H_c = chat_R_c - (chat_t_c @ c_n.T) / P[2]\n",
    "            chat_H_c = chat_H_c / chat_H_c[2, 2]\n",
    "            p = P / P[2]\n",
    "            s.append((chat_H_c[2] @ p).item())\n",
    "    return np.array(s)\n",
    "\n",
    "def save_view_point(geos, filename):\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    for geo in geos:\n",
    "        vis.add_geometry(geo)\n",
    "    vis.run()  # user changes the view and press \"q\" to terminate\n",
    "    param = vis.get_view_control().convert_to_pinhole_camera_parameters()\n",
    "    o3d.io.write_pinhole_camera_parameters(filename, param)\n",
    "    vis.destroy_window()\n",
    "\n",
    "def compute_ABC(w_t_c, c_R_w, w_t_chat, chat_R_w):\n",
    "    c_n = torch.tensor([0, 0, -1], dtype=torch.float64).view(3, 1)\n",
    "    eye = torch.eye(3, dtype=torch.float64)\n",
    "    chat_t_c = chat_R_w @ (w_t_c - w_t_chat)\n",
    "    chat_R_c = chat_R_w @ c_R_w.T\n",
    "\n",
    "    A = eye - chat_R_c\n",
    "    C = c_n @ chat_t_c.T\n",
    "    B = C @ A\n",
    "    A = A @ A.T\n",
    "    B = B + B.T\n",
    "    C = C @ C.T\n",
    "\n",
    "    return A, B, C\n",
    "\n",
    "def quaternion_to_R(q):\n",
    "    qw, qx, qy, qz = q\n",
    "    return np.array([\n",
    "        [1 - 2 * (np.square(qy) + np.square(qz)), 2 * (qx * qy - qw * qz), 2 * (qw * qy + qx * qz)],\n",
    "        [2 * (qx * qy + qw * qz), 1 - 2 * (np.square(qx) + np.square(qz)), 2 * (qy * qz - qw * qx)],\n",
    "        [2 * (qx * qz - qw * qy), 2 * (qw * qx + qy * qz), 1 - 2 * (np.square(qx) + np.square(qy))]\n",
    "    ])\n",
    "\n",
    "def posenet(w_t_chat, w_t_c, chat_q_w, c_q_w):\n",
    "    return torch.square(w_t_chat - w_t_c).sum().sqrt() + 0.2 * torch.square(chat_q_w - c_q_w).sum().sqrt()\n",
    "\n",
    "def geometric(w_t_chat, w_t_c, chat_q_w, c_R_w, w_P):\n",
    "    c_p = project(w_t_c, c_R_w, w_P)\n",
    "    chat_p = project(w_t_chat, quaternion_to_rotation_matrix(chat_q_w, order=QuaternionCoeffOrder.WXYZ), w_P)\n",
    "    return torch.nn.functional.mse_loss(chat_p, c_p)\n",
    "    #return torch.abs(chat_p - c_p).sum(dim=0).mean()\n",
    "\n",
    "def homographic(w_t_c, c_R_w, w_t_chat, chat_q_w, xmin, xmax):\n",
    "    A, B, C = compute_ABC(w_t_c, c_R_w, w_t_chat, quaternion_to_rotation_matrix(chat_q_w, order=QuaternionCoeffOrder.WXYZ))\n",
    "    B_weight = torch.log(xmax / xmin) / (xmax - xmin)\n",
    "    C_weight = xmin * xmax\n",
    "    error = A + B * B_weight + C / C_weight\n",
    "    return error.trace()\n",
    "\n",
    "def get_data(path):\n",
    "    views = []\n",
    "    scene_coordinates = []\n",
    "    rgb = []\n",
    "\n",
    "    with open(path / 'reconstruction.nvm', 'r') as file:\n",
    "\n",
    "        # Skip first two lines\n",
    "        for _ in range(2):\n",
    "            file.readline()\n",
    "\n",
    "        # `n_views` is the number of images\n",
    "        n_views = int(file.readline())\n",
    "\n",
    "        # For each image, NVM format is:\n",
    "        # <File name> <focal length> <quaternion WXYZ> <camera center> <radial distortion> 0\n",
    "        for _ in range(n_views):\n",
    "            line = file.readline().split()\n",
    "\n",
    "            f = float(line[1])\n",
    "            K = np.array([\n",
    "                [f, 0, 1920 / 2],\n",
    "                [0, f, 1080 / 2],\n",
    "                [0, 0, 1]\n",
    "            ])\n",
    "            views.append({\n",
    "                'image_file': line[0],\n",
    "                'K': K,\n",
    "                'observations_ids': []\n",
    "            })\n",
    "\n",
    "        # Skip one line\n",
    "        file.readline()\n",
    "\n",
    "        # `n_points` is the number of scene coordinates\n",
    "        n_points = int(file.readline())\n",
    "\n",
    "        # For each scene coordinate, SVM format is:\n",
    "        # <XYZ> <RGB> <number of measurements> <List of Measurements>\n",
    "        for i in range(n_points):\n",
    "\n",
    "            line = file.readline().split()\n",
    "\n",
    "            scene_coordinates.append(np.array(list(map(float, line[:3]))))\n",
    "            rgb.append(np.array(list(map(int, line[3:6]))))\n",
    "\n",
    "            # `n_obs` is the number of images where the scene coordinate is observed\n",
    "            n_obs = int(line[6])\n",
    "\n",
    "            # Each measurement is\n",
    "            # <Image index> <Feature Index> <xy>\n",
    "            for n in range(n_obs):\n",
    "                views[int(line[7 + n * 4])]['observations_ids'].append(i)\n",
    "\n",
    "    views = {view.pop('image_file'): view for view in views}\n",
    "    scene_coordinates = np.stack(scene_coordinates)\n",
    "    rgb = np.stack(rgb)\n",
    "\n",
    "    df = pd.read_csv(path / 'dataset_train.txt', sep=' ', skiprows=1)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for image_file, w_t_c, c_q_w in zip(df.iloc[:, 0].values, df.iloc[:, 1:4].values, df.iloc[:, 4:8].values):\n",
    "        w_t_c = w_t_c.reshape(3, 1)\n",
    "        c_q_w = c_q_w / np.linalg.norm(c_q_w)\n",
    "        c_R_w = quaternion_to_R(c_q_w)\n",
    "        view = views[os.path.splitext(image_file)[0] + '.jpg']\n",
    "        w_P = scene_coordinates[view['observations_ids']]\n",
    "        colors = rgb[view['observations_ids']]\n",
    "        c_P = c_R_w @ (w_P.T - w_t_c)\n",
    "        c_p = view['K'] @ c_P\n",
    "        c_p = c_p[:2] / c_p[2]\n",
    "        args_inliers = np.argwhere(\n",
    "            (c_P[2] > 0.2) & (c_P[2] < 1000) & (np.abs(c_P[0]) < 1000) & (np.abs(c_P[1]) < 1000) & \\\n",
    "            (c_p[0] > 0) & (c_p[0] < 1920) & (c_p[1] > 0) & (c_p[1] < 1080)\n",
    "        ).flatten()\n",
    "        if args_inliers.shape[0] < 10:\n",
    "            print(f'Not using image {image_file}: [{args_inliers.shape[0]}/{w_P.shape[0]}] scene coordinates inliers')\n",
    "        elif np.abs(w_t_c).max() > 1000:\n",
    "            print(f'Not using image {image_file}: t is {w_t_c}')\n",
    "        else:\n",
    "            if args_inliers.shape[0] != w_P.shape[0]:\n",
    "                print(f'Eliminating outliers in image {image_file}: [{args_inliers.shape[0]}/{w_P.shape[0]}] scene coordinates inliers')\n",
    "            depths = np.sort(c_P.T[args_inliers][:, 2])\n",
    "            data.append({\n",
    "                'image_file': image_file,\n",
    "                'w_t_c': w_t_c,\n",
    "                'c_q_w': c_q_w,\n",
    "                'c_R_w': c_R_w,\n",
    "                'w_P': w_P[args_inliers],\n",
    "                'c_p': c_p.T[args_inliers],\n",
    "                'K': view['K'],\n",
    "                'rgb': colors[args_inliers],\n",
    "                'xmin': depths[int(0.025 * (depths.shape[0] - 1))],\n",
    "                'xmax': depths[int(0.975 * (depths.shape[0] - 1))]\n",
    "            })\n",
    "    return data\n",
    "\n",
    "path = Path('/media/clementin/DATA/Cambridge/KingsCollege')\n",
    "\n",
    "camera_mesh = o3d.io.read_triangle_mesh('/home/clementin/Dev/underwater_reloc_benchmark/Hierarchical-Localization/outputs/TourEiffel/camera_insideout.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d7d5c-a73e-42ab-a117-1e97f4ce4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba62dc3-2fba-497f-80b2-34e9604fb3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = data[420]\n",
    "\n",
    "w_P = torch.tensor(image['w_P'])\n",
    "w_t_c = torch.tensor(image['w_t_c'])\n",
    "c_q_w = torch.tensor(image['c_q_w'])\n",
    "xmin = torch.tensor(image['xmin'])\n",
    "xmax = torch.tensor(image['xmax'])\n",
    "K = torch.tensor(image['K'])\n",
    "c_R_w = quaternion_to_rotation_matrix(c_q_w, order=QuaternionCoeffOrder.WXYZ)\n",
    "w_R_c = c_R_w.T\n",
    "c_P = c_R_w @ (w_P.T - w_t_c)\n",
    "\n",
    "gt_cam = o3d.geometry.TriangleMesh(camera_mesh)\n",
    "gt_cam.paint_uniform_color([0, 0.709, 0])\n",
    "gt_cam.transform(np.vstack([\n",
    "    np.hstack([w_R_c.numpy(), w_t_c.numpy()]),\n",
    "    [0, 0, 0, 1]\n",
    "]))\n",
    "\n",
    "es_cam = o3d.geometry.TriangleMesh(camera_mesh)\n",
    "es_cam.paint_uniform_color([0.709, 0, 0])\n",
    "\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(image['w_P'])\n",
    "point_cloud.colors = o3d.utility.Vector3dVector(image['rgb'] / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99979fcd-6817-457c-99bd-ce7979e8b64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_q_w = c_q_w.clone()\n",
    "w_t_chat = w_t_c.clone()\n",
    "chat_q_w[1:] *= -1\n",
    "#chat_q_w += torch.tensor([0.2, -0.08, 0.1, -0.14])\n",
    "w_t_chat += torch.tensor([-2, -2, 2]).view(3, 1)\n",
    "chat_q_w = torch.nn.Parameter(chat_q_w)\n",
    "w_t_chat = torch.nn.Parameter(w_t_chat)\n",
    "\n",
    "optimizer = torch.optim.Adam([chat_q_w, w_t_chat])\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(gt_cam)\n",
    "vis.add_geometry(es_cam)\n",
    "vis.add_geometry(point_cloud)\n",
    "\n",
    "for epoch in range(500):\n",
    "    \n",
    "    for _ in range(2):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #loss = geometric(w_t_chat, w_t_c, chat_q_w, c_R_w, w_P)\n",
    "        loss = homographic(w_t_c, c_R_w, w_t_chat, chat_q_w, xmin, xmax)\n",
    "        #loss = posenet(w_t_chat, w_t_c, chat_q_w, c_q_w)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        s = compute_s(chat_q_w, c_R_w, w_t_chat, w_t_c, c_P, xmin, xmax)\n",
    "        s_max = max(0.01, np.abs(s - 1).max())\n",
    "        bins = np.linspace(-s_max + 1, s_max + 1, 10)\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.hist(s, bins=bins, color=[0.709, 0.0, 0.0])\n",
    "        plt.gca().spines['right'].set_visible(False)\n",
    "        plt.gca().spines['top'].set_visible(False)\n",
    "        plt.title('Repartition of $s$', y=-0.18)\n",
    "        plt.savefig(f's/{epoch:05d}.png', facecolor='white')\n",
    "        plt.close()\n",
    "        \n",
    "        disp_chat_R_w = quaternion_to_rotation_matrix(chat_q_w, order=QuaternionCoeffOrder.WXYZ).detach().numpy()\n",
    "        disp_w_t_chat = w_t_chat.detach().numpy()\n",
    "        es_cam.transform(np.vstack([\n",
    "            np.hstack([disp_chat_R_w.T, disp_w_t_chat]),\n",
    "            [0, 0, 0, 1]\n",
    "        ]))\n",
    "        vis.update_geometry(es_cam)\n",
    "        vis.get_view_control().convert_from_pinhole_camera_parameters(o3d.io.read_pinhole_camera_parameters('render_homography.json'))\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        vis.capture_screen_image(f'im/{epoch:05d}.png')\n",
    "        if epoch % 100 == 0:\n",
    "            gs_cam = o3d.geometry.TriangleMesh(es_cam)\n",
    "            gs_cam.paint_uniform_color([0.709, 0.5, 0.5])\n",
    "            vis.add_geometry(gs_cam)\n",
    "        es_cam.transform(np.vstack([\n",
    "            np.hstack([disp_chat_R_w, -disp_chat_R_w @ disp_w_t_chat]),\n",
    "            [0, 0, 0, 1]\n",
    "        ]))\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f138d-1d55-47ef-9229-21f7fee2d558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
